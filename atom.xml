<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Fred Fang&#39;s blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-11-12T08:23:47.756Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Fred Fang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>About-Me</title>
    <link href="http://yoursite.com/2019/11/12/About-Me/"/>
    <id>http://yoursite.com/2019/11/12/About-Me/</id>
    <published>2019-11-12T08:21:08.000Z</published>
    <updated>2019-11-12T08:23:47.756Z</updated>
    
    <content type="html"><![CDATA[<p>Name:<strong>方逸凡 Fang Yifan</strong></p><p>English Name :<strong>Fred</strong></p><p>Gender: <strong>Male</strong></p><p>Birthday: <strong>April 15th, 2002</strong></p><p>School:<strong>Hangzhou Foreign Language School</strong>    </p><p>Future Major(s): <strong>math, computer science</strong></p><p>Interests : <strong>science and technology, table tennis, watching movies, travelling</strong></p><p>Email: <strong><a href="mailto:1289899092@qq.com" target="_blank" rel="noopener">1289899092@qq.com</a></strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Name:&lt;strong&gt;方逸凡 Fang Yifan&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;English Name :&lt;strong&gt;Fred&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Gender: &lt;strong&gt;Male&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Birthday: &lt;st
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Project-Summary</title>
    <link href="http://yoursite.com/2019/10/30/Project-Summary/"/>
    <id>http://yoursite.com/2019/10/30/Project-Summary/</id>
    <published>2019-10-30T05:56:33.000Z</published>
    <updated>2019-10-30T06:39:00.916Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Home-Credit-Default-Risk"><a href="#Home-Credit-Default-Risk" class="headerlink" title="Home Credit Default Risk"></a>Home Credit Default Risk</h2><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Many people struggle to get loans due to insufficient credit histories. In order to ensure that clients capable of repayment are given loans, which can help them to be successful, I utilize a variety of alternative data–including telco and transactional information–to predict clients’ repayment abilities. This is a supervised two-class classification problem of machine learning, and my project aims to predict whether banks should give loans to the client.</p><h3 id="Preprocessing"><a href="#Preprocessing" class="headerlink" title="Preprocessing"></a>Preprocessing</h3><h4 id="Data-balance"><a href="#Data-balance" class="headerlink" title="Data balance"></a>Data balance</h4><p>I split the “train” file in to train set and test set to validate the model. I randomly select 80 percent of rows with target 1 in “train” file and equivalent amount of rows with target 0 “train” file to constitute the train set. The test set consists of 20 percent remaining rows with target 1 and equivalent rows with target 0. This process serves to eliminate the possible influence of biases.</p><p><img src="/2019/10/30/Project-Summary/1.png" alt="1"></p><h4 id="Remove-bad-features-columns-and-records-row"><a href="#Remove-bad-features-columns-and-records-row" class="headerlink" title="Remove bad features (columns) and records (row)"></a>Remove bad features (columns) and records (row)</h4><p>I eliminate the rows and columns which have more than 40 percent blank space, because they have little value for reference. </p><p><img src="/2019/10/30/Project-Summary/2.png" alt="2"></p><h3 id="Visualization"><a href="#Visualization" class="headerlink" title="Visualization"></a>Visualization</h3><p>Data exploration and visualization serves to represent messy data on graphs, which enable people to see the correlation between data clearly and directly. Therefore, we can analyze patterns on the graphs and forecast future trends of certain events. If the data in the column do not have distinct influence on the TARGET column, I will delete this column. This process aims to determine which column needs to be included in feature engineering.</p><p><img src="/2019/10/30/Project-Summary/3.png" alt="3"></p><p>From the plot education and income, we can see that higher the level of education the client achieved, more income the client received.</p><p><img src="/2019/10/30/Project-Summary/4.png" alt="4"></p><p>From the plot income type (hue TARGET), we can see that people who receive income from working may be more difficult to get the loan in the further.</p><p><img src="/2019/10/30/Project-Summary/5.png" alt="5"></p><p>From the plot family status (hue TARGET), we can see that people who are married or widows may be easier to get the loan in the further.</p><p><img src="/2019/10/30/Project-Summary/6.png" alt="6"></p><p>From the plot housing type (hue TARGET), we can see that people who own apartments may be more capable of getting loans.</p><p><img src="/2019/10/30/Project-Summary/7.png" alt="7"></p><p>From the plot occupation type (hue TARGET), we can see that laborers are the least convincing among all the occupations.</p><p><img src="/2019/10/30/Project-Summary/8.png" alt="8"></p><p>From the plot, we can see that the day of the week which the client apply for the loan does not influence too much. </p><p><img src="/2019/10/30/Project-Summary/9.png" alt="9"></p><p>From the graph, we can discover that all the people in the sample provide mobile phone numbers, so it would not be an indicator of whether the banks should lend money to them.</p><h3 id="Feature-engineering"><a href="#Feature-engineering" class="headerlink" title="Feature engineering"></a>Feature engineering</h3><h4 id="Integer-encoding-and-one-hot-encoding"><a href="#Integer-encoding-and-one-hot-encoding" class="headerlink" title="Integer encoding and one-hot encoding"></a>Integer encoding and one-hot encoding</h4><p>Feature engineering is the process of using domain knowledge of the data to create or modify features to make machine-learning algorithms work. Feature engineering has two techniques: integer encoding, which is an algorithm mapping the category variable with integer, and one-hot encoding, which utilizes high (1) bits and low bits (0) to represent the data. In statistics, dummy variables represent a similar technique for representing categorical data. One-hot encoding is easy to design and modify. In addition, using a one-hot implementation typically allows a state machine to run at a faster clock rate than any other encoding of that state machine. However, one-hot encoding requires more storage than other encodings, and it may loss some information in some circumstance. It does not work effectively with too many categories. Through feature engineering, we can extract features from raw data to fit in algorithms and models. These features can make the data more understandable to machines and improve the function of the algorithms and models. If the data has increase or decrease by degrees, we usually use integer encoding. Otherwise, it is proper to use one-hot encoding.</p><h4 id="Grouping"><a href="#Grouping" class="headerlink" title="Grouping"></a>Grouping</h4><p>Grouping is the process of combining or dividing primary data into groups based on specific criteria. We can transform data into numerical data, using 0 or 1 to represent the data, and categorical data, classifying data into different categories. The grouping of data enables us to discover certain data distribution characteristics, which facilitates us to explore the correlation between two sets of data. Besides, the computer can better understand these data after grouping.</p><h4 id="Data-reduction"><a href="#Data-reduction" class="headerlink" title="Data reduction"></a>Data reduction</h4><p>Data reduction is the transformation of numerical or alphabetical digital information derived empirically or experimentally into a corrected, ordered, and simplified form. The basic concept is the reduction of multitudinous amounts of data down to the meaningful parts.</p><h3 id="Models-and-results"><a href="#Models-and-results" class="headerlink" title="Models and results"></a>Models and results</h3><h4 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h4><p>Logistic regression is a machine learning model for binary variable.</p><p><img src="/2019/10/30/Project-Summary/10.png" alt="10"></p><h4 id="Recursive-Feature-Elimination-RFE"><a href="#Recursive-Feature-Elimination-RFE" class="headerlink" title="Recursive Feature Elimination (RFE)"></a>Recursive Feature Elimination (RFE)</h4><p>Recursive feature elimination is based on the idea to repeatedly construct a model (for example an SVM or a regression model) and choose either the best or worst performing feature (for example based on coefficients), setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. Features are then ranked according to when they were eliminated. As such, it is a greedy optimization for finding the best performing subset of features.</p><p><img src="/2019/10/30/Project-Summary/11.png" alt="11"></p><h4 id="Principal-component-analysis-PCA"><a href="#Principal-component-analysis-PCA" class="headerlink" title="Principal component analysis (PCA)"></a>Principal component analysis (PCA)</h4><p>Principal component analysis (PCA) is a statistical procedure that uses an orthogonal transformation to convert a set of observations of possibly correlated variables (entities each of which takes on various numerical values) into a set of values of linearly uncorrelated variables called principal components.</p><h4 id="Optimization-of-Principal-component-analysis-PCA-Model"><a href="#Optimization-of-Principal-component-analysis-PCA-Model" class="headerlink" title="Optimization of Principal component analysis (PCA) Model"></a>Optimization of Principal component analysis (PCA) Model</h4><p>I changes the n_components of PCA model from 1 to 30 to see the result of accuracy. In the first plot below, x-axis is the n_components of PCA model and y-axis shows the accuracy. We can see from the plat that the accuracy increases until n_components=9 and the accuracy is almost same when n_components is higher than 9. In addition, when intercept_scaling=1000, the accuracy reaches its maximum of 60.429%.</p><p><img src="/2019/10/30/Project-Summary/12.png" alt="12"></p><p><img src="/2019/10/30/Project-Summary/13.png" alt="13"></p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>In this project, I predict whether banks should lend money to clients. I remove bad columns and rows, and reduce the features of the model. Finally I used logistic regression with dimensional reduction principal component analysis (n_components=9, intercept_scaling=1000) to do the prediction. The accuracy of the final model is 60.429%. Principal component analysis (PCA) improves the accuracy of the model. However, recursive feature elimination does not help with the accuracy of the model, but I believe that changing the parameters in recursive feature elimination (RFE) model may bring some improvements.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;Home-Credit-Default-Risk&quot;&gt;&lt;a href=&quot;#Home-Credit-Default-Risk&quot; class=&quot;headerlink&quot; title=&quot;Home Credit Default Risk&quot;&gt;&lt;/a&gt;Home Credit De
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Coding-Demonstration</title>
    <link href="http://yoursite.com/2019/10/11/Coding-Demonstration/"/>
    <id>http://yoursite.com/2019/10/11/Coding-Demonstration/</id>
    <published>2019-10-11T08:27:06.000Z</published>
    <updated>2019-11-12T08:41:35.359Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Home-Credit"><a href="#Home-Credit" class="headerlink" title="Home Credit"></a>Home Credit</h1><h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><p>Many people struggle to get loans due to insufficient or non-existent credit histories. And, unfortunately, this population is often taken advantage of by untrustworthy lenders.</p><p>Home Credit strives to broaden financial inclusion for the unbanked population by providing a positive and safe borrowing experience. In order to make sure this underserved population has a positive loan experience, Home Credit makes use of a variety of alternative data–including telco and transactional information–to predict their clients’ repayment abilities.</p><p>While Home Credit is currently using various statistical and machine learning methods to make these predictions, they’re challenging Kagglers to help them unlock the full potential of their data. Doing so will ensure that clients capable of repayment are not rejected and that loans are given with a principal, maturity, and repayment calendar that will empower their clients to be successful.</p><h2 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h2><h3 id="application-train-test-csv"><a href="#application-train-test-csv" class="headerlink" title="application_{train|test}.csv"></a>application_{train|test}.csv</h3><p>This is the main table, broken into two files for Train (with TARGET) and Test (without TARGET).<br>Static data for all applications. One row represents one loan in our data sample.</p><table><thead><tr><th align="left"><strong>Row</strong></th><th align="left"><strong>Description</strong></th></tr></thead><tbody><tr><td align="left">SK_ID_CURR</td><td align="left">ID of loan in our sample</td></tr><tr><td align="left">TARGET</td><td align="left">Target variable (1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample, 0 - all other cases)</td></tr><tr><td align="left">NAME_CONTRACT_TYPE</td><td align="left">Identification if loan is cash or revolving</td></tr><tr><td align="left">CODE_GENDER</td><td align="left">Gender of the client</td></tr><tr><td align="left">FLAG_OWN_CAR</td><td align="left">Flag if the client owns a car</td></tr><tr><td align="left">FLAG_OWN_REALTY</td><td align="left">Flag if client owns a house or flat</td></tr><tr><td align="left">CNT_CHILDREN</td><td align="left">Number of children the client has</td></tr><tr><td align="left">AMT_INCOME_TOTAL</td><td align="left">Income of the client</td></tr><tr><td align="left">AMT_CREDIT</td><td align="left">Credit amount of the loan</td></tr><tr><td align="left">AMT_ANNUITY</td><td align="left">Loan annuity</td></tr><tr><td align="left">AMT_GOODS_PRICE</td><td align="left">For consumer loans it is the price of the goods for which the loan is given</td></tr><tr><td align="left">NAME_TYPE_SUITE</td><td align="left">Who was accompanying client when he was applying for the loan</td></tr><tr><td align="left">NAME_INCOME_TYPE</td><td align="left">Clients income type (businessman, working, maternity leave,…)</td></tr><tr><td align="left">NAME_EDUCATION_TYPE</td><td align="left">Level of highest education the client achieved</td></tr><tr><td align="left">NAME_FAMILY_STATUS</td><td align="left">Family status of the client</td></tr><tr><td align="left">NAME_HOUSING_TYPE</td><td align="left">What is the housing situation of the client (renting, living with parents, …)</td></tr><tr><td align="left">REGION_POPULATION_RELATIVE</td><td align="left">Normalized population of region where client lives (higher number means the client lives in more populated region)</td></tr><tr><td align="left">DAYS_BIRTH</td><td align="left">Client’s age in days at the time of application</td></tr><tr><td align="left">DAYS_EMPLOYED</td><td align="left">How many days before the application the person started current employment</td></tr><tr><td align="left">DAYS_REGISTRATION</td><td align="left">How many days before the application did client change his registration</td></tr><tr><td align="left">DAYS_ID_PUBLISH</td><td align="left">How many days before the application did client change the identity document with which he applied for the loan</td></tr><tr><td align="left">OWN_CAR_AGE</td><td align="left">Age of client’s car</td></tr><tr><td align="left">FLAG_MOBIL</td><td align="left">Did client provide mobile phone (1=YES, 0=NO)</td></tr><tr><td align="left">FLAG_EMP_PHONE</td><td align="left">Did client provide work phone (1=YES, 0=NO)</td></tr><tr><td align="left">FLAG_WORK_PHONE</td><td align="left">Did client provide home phone (1=YES, 0=NO)</td></tr><tr><td align="left">FLAG_CONT_MOBILE</td><td align="left">Was mobile phone reachable (1=YES, 0=NO)</td></tr><tr><td align="left">FLAG_PHONE</td><td align="left">Did client provide home phone (1=YES, 0=NO)</td></tr><tr><td align="left">FLAG_EMAIL</td><td align="left">Did client provide email (1=YES, 0=NO)</td></tr><tr><td align="left">OCCUPATION_TYPE</td><td align="left">What kind of occupation does the client have</td></tr><tr><td align="left">CNT_FAM_MEMBERS</td><td align="left">How many family members does client have</td></tr><tr><td align="left">REGION_RATING_CLIENT</td><td align="left">Our rating of the region where client lives (1,2,3)</td></tr><tr><td align="left">REGION_RATING_CLIENT_W_CITY</td><td align="left">Our rating of the region where client lives with taking city into account (1,2,3)</td></tr><tr><td align="left">WEEKDAY_APPR_PROCESS_START</td><td align="left">On which day of the week did the client apply for the loan</td></tr><tr><td align="left">HOUR_APPR_PROCESS_START</td><td align="left">Approximately at what hour did the client apply for the loan</td></tr><tr><td align="left">REG_REGION_NOT_LIVE_REGION</td><td align="left">Flag if client’s permanent address does not match contact address (1=different, 0=same, at region level)</td></tr><tr><td align="left">REG_REGION_NOT_WORK_REGION</td><td align="left">Flag if client’s permanent address does not match work address (1=different, 0=same, at region level)</td></tr><tr><td align="left">LIVE_REGION_NOT_WORK_REGION</td><td align="left">Flag if client’s contact address does not match work address (1=different, 0=same, at region level)</td></tr><tr><td align="left">REG_CITY_NOT_LIVE_CITY</td><td align="left">Flag if client’s permanent address does not match contact address (1=different, 0=same, at city level)</td></tr><tr><td align="left">REG_CITY_NOT_WORK_CITY</td><td align="left">Flag if client’s permanent address does not match work address (1=different, 0=same, at city level)</td></tr><tr><td align="left">LIVE_CITY_NOT_WORK_CITY</td><td align="left">Flag if client’s contact address does not match work address (1=different, 0=same, at city level)</td></tr><tr><td align="left">ORGANIZATION_TYPE</td><td align="left">Type of organization where client works</td></tr><tr><td align="left">EXT_SOURCE_1</td><td align="left">Normalized score from external data source</td></tr><tr><td align="left">EXT_SOURCE_2</td><td align="left">Normalized score from external data source</td></tr><tr><td align="left">EXT_SOURCE_3</td><td align="left">Normalized score from external data source</td></tr><tr><td align="left">APARTMENTS_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">BASEMENTAREA_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">YEARS_BEGINEXPLUATATION_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">YEARS_BUILD_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">COMMONAREA_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">ELEVATORS_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">ENTRANCES_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">FLOORSMAX_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">FLOORSMIN_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">LANDAREA_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">LIVINGAPARTMENTS_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">LIVINGAREA_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">NONLIVINGAPARTMENTS_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">NONLIVINGAREA_AVG</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">APARTMENTS_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">BASEMENTAREA_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">YEARS_BEGINEXPLUATATION_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">YEARS_BUILD_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">COMMONAREA_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">ELEVATORS_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">ENTRANCES_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">FLOORSMAX_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">FLOORSMIN_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">LANDAREA_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">LIVINGAPARTMENTS_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">LIVINGAREA_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">NONLIVINGAPARTMENTS_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">NONLIVINGAREA_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">APARTMENTS_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">BASEMENTAREA_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">YEARS_BEGINEXPLUATATION_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">YEARS_BUILD_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">COMMONAREA_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">ELEVATORS_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">ENTRANCES_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">FLOORSMAX_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">FLOORSMIN_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">LANDAREA_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">LIVINGAPARTMENTS_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">LIVINGAREA_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">NONLIVINGAPARTMENTS_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">NONLIVINGAREA_MEDI</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">FONDKAPREMONT_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">HOUSETYPE_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">TOTALAREA_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">WALLSMATERIAL_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">EMERGENCYSTATE_MODE</td><td align="left">Normalized information about building where the client lives, What is average (_AVG suffix), modus (_MODE suffix), median (_MEDI suffix) apartment size, common area, living area, age of building, number of elevators, number of entrances, state of the building, number of floor</td></tr><tr><td align="left">OBS_30_CNT_SOCIAL_CIRCLE</td><td align="left">How many observation of client’s social surroundings with observable 30 DPD (days past due) default</td></tr><tr><td align="left">DEF_30_CNT_SOCIAL_CIRCLE</td><td align="left">How many observation of client’s social surroundings defaulted on 30 DPD (days past due)</td></tr><tr><td align="left">OBS_60_CNT_SOCIAL_CIRCLE</td><td align="left">How many observation of client’s social surroundings with observable 60 DPD (days past due) default</td></tr><tr><td align="left">DEF_60_CNT_SOCIAL_CIRCLE</td><td align="left">How many observation of client’s social surroundings defaulted on 60 (days past due) DPD</td></tr><tr><td align="left">DAYS_LAST_PHONE_CHANGE</td><td align="left">How many days before application did client change phone</td></tr><tr><td align="left">FLAG_DOCUMENT_2</td><td align="left">Did client provide document 2</td></tr><tr><td align="left">FLAG_DOCUMENT_3</td><td align="left">Did client provide document 3</td></tr><tr><td align="left">FLAG_DOCUMENT_4</td><td align="left">Did client provide document 4</td></tr><tr><td align="left">FLAG_DOCUMENT_5</td><td align="left">Did client provide document 5</td></tr><tr><td align="left">FLAG_DOCUMENT_6</td><td align="left">Did client provide document 6</td></tr><tr><td align="left">FLAG_DOCUMENT_7</td><td align="left">Did client provide document 7</td></tr><tr><td align="left">FLAG_DOCUMENT_8</td><td align="left">Did client provide document 8</td></tr><tr><td align="left">FLAG_DOCUMENT_9</td><td align="left">Did client provide document 9</td></tr><tr><td align="left">FLAG_DOCUMENT_10</td><td align="left">Did client provide document 10</td></tr><tr><td align="left">FLAG_DOCUMENT_11</td><td align="left">Did client provide document 11</td></tr><tr><td align="left">FLAG_DOCUMENT_12</td><td align="left">Did client provide document 12</td></tr><tr><td align="left">FLAG_DOCUMENT_13</td><td align="left">Did client provide document 13</td></tr><tr><td align="left">FLAG_DOCUMENT_14</td><td align="left">Did client provide document 14</td></tr><tr><td align="left">FLAG_DOCUMENT_15</td><td align="left">Did client provide document 15</td></tr><tr><td align="left">FLAG_DOCUMENT_16</td><td align="left">Did client provide document 16</td></tr><tr><td align="left">FLAG_DOCUMENT_17</td><td align="left">Did client provide document 17</td></tr><tr><td align="left">FLAG_DOCUMENT_18</td><td align="left">Did client provide document 18</td></tr><tr><td align="left">FLAG_DOCUMENT_19</td><td align="left">Did client provide document 19</td></tr><tr><td align="left">FLAG_DOCUMENT_20</td><td align="left">Did client provide document 20</td></tr><tr><td align="left">FLAG_DOCUMENT_21</td><td align="left">Did client provide document 21</td></tr><tr><td align="left">AMT_REQ_CREDIT_BUREAU_HOUR</td><td align="left">Number of enquiries to Credit Bureau about the client one hour before application</td></tr><tr><td align="left">AMT_REQ_CREDIT_BUREAU_DAY</td><td align="left">Number of enquiries to Credit Bureau about the client one day before application (excluding one hour before application)</td></tr><tr><td align="left">AMT_REQ_CREDIT_BUREAU_WEEK</td><td align="left">Number of enquiries to Credit Bureau about the client one week before application (excluding one day before application)</td></tr><tr><td align="left">AMT_REQ_CREDIT_BUREAU_MON</td><td align="left">Number of enquiries to Credit Bureau about the client one month before application (excluding one week before application)</td></tr><tr><td align="left">AMT_REQ_CREDIT_BUREAU_QRT</td><td align="left">Number of enquiries to Credit Bureau about the client 3 month before application (excluding one month before application)</td></tr><tr><td align="left">AMT_REQ_CREDIT_BUREAU_YEAR</td><td align="left">Number of enquiries to Credit Bureau about the client one day year (excluding last 3 months before application)</td></tr></tbody></table><h2 id="Project-model"><a href="#Project-model" class="headerlink" title="Project model"></a>Project model</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># numpy and pandas for data manipulation</span></span><br><span class="line"><span class="comment"># matplotlib and seaborn for plotting</span></span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="comment"># File system manangement</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> RFECV</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Counter to show whether the data is balanced.</span></span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="comment"># Suppress warnings</span></span><br><span class="line"><span class="keyword">import</span> warnings</span><br><span class="line">warnings.filterwarnings(<span class="string">'ignore'</span>)</span><br></pre></td></tr></table></figure><h3 id="Load-data"><a href="#Load-data" class="headerlink" title="Load data"></a>Load data</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out_df_1000 = pd.read_csv(<span class="string">'./input/application_train.csv'</span>)<span class="comment">#, nrows=10000)  # full data shape: (307511, 122)</span></span><br><span class="line">out_df_1000.shape</span><br></pre></td></tr></table></figure><pre><code>(307511, 122)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_df_1000.head()</span><br></pre></td></tr></table></figure><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th {    vertical-align: top;}.dataframe thead th {    text-align: right;}</code></pre><p></style><p></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>SK_ID_CURR</th>      <th>TARGET</th>      <th>NAME_CONTRACT_TYPE</th>      <th>CODE_GENDER</th>      <th>FLAG_OWN_CAR</th>      <th>FLAG_OWN_REALTY</th>      <th>CNT_CHILDREN</th>      <th>AMT_INCOME_TOTAL</th>      <th>AMT_CREDIT</th>      <th>AMT_ANNUITY</th>      <th>...</th>      <th>FLAG_DOCUMENT_18</th>      <th>FLAG_DOCUMENT_19</th>      <th>FLAG_DOCUMENT_20</th>      <th>FLAG_DOCUMENT_21</th>      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>      <th>AMT_REQ_CREDIT_BUREAU_MON</th>      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>    </tr>  </thead>  <tbody>    <tr>      <td>0</td>      <td>100002</td>      <td>1</td>      <td>Cash loans</td>      <td>M</td>      <td>N</td>      <td>Y</td>      <td>0</td>      <td>202500.0</td>      <td>406597.5</td>      <td>24700.5</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>1.0</td>    </tr>    <tr>      <td>1</td>      <td>100003</td>      <td>0</td>      <td>Cash loans</td>      <td>F</td>      <td>N</td>      <td>N</td>      <td>0</td>      <td>270000.0</td>      <td>1293502.5</td>      <td>35698.5</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>    <tr>      <td>2</td>      <td>100004</td>      <td>0</td>      <td>Revolving loans</td>      <td>M</td>      <td>Y</td>      <td>Y</td>      <td>0</td>      <td>67500.0</td>      <td>135000.0</td>      <td>6750.0</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>    <tr>      <td>3</td>      <td>100006</td>      <td>0</td>      <td>Cash loans</td>      <td>F</td>      <td>N</td>      <td>Y</td>      <td>0</td>      <td>135000.0</td>      <td>312682.5</td>      <td>29686.5</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <td>4</td>      <td>100007</td>      <td>0</td>      <td>Cash loans</td>      <td>M</td>      <td>N</td>      <td>Y</td>      <td>0</td>      <td>121500.0</td>      <td>513000.0</td>      <td>21865.5</td>      <td>...</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>  </tbody></table><p>5 rows × 122 columns</p></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Counter(out_df_1000.TARGET)</span><br></pre></td></tr></table></figure><pre><code>Counter({1: 24825, 0: 282686})</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(out_df_1000.TARGET)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x20aa797db88&gt;</code></pre><p><img src="/2019/10/11/Coding-Demonstration/1.png" alt="png"></p><h3 id="Data-Balance"><a href="#Data-Balance" class="headerlink" title="Data Balance"></a>Data Balance</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sample_num = int(out_df_1000[out_df_1000.TARGET == <span class="number">1</span>].shape[<span class="number">0</span>]*<span class="number">0.8</span>)</span><br><span class="line">print(sample_num)</span><br><span class="line"></span><br><span class="line">out_df_1000 = pd.concat([out_df_1000[out_df_1000.TARGET == <span class="number">1</span>].sample(</span><br><span class="line">    sample_num), out_df_1000[out_df_1000.TARGET == <span class="number">0</span>].sample(sample_num)], ignore_index=<span class="literal">True</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">print(Counter(out_df_1000.TARGET))</span><br><span class="line">sns.countplot(out_df_1000.TARGET)</span><br></pre></td></tr></table></figure><pre><code>19860Counter({1: 19860, 0: 19860})&lt;matplotlib.axes._subplots.AxesSubplot at 0x20aa8161188&gt;</code></pre><p><img src="/2019/10/11/Coding-Demonstration/2.png" alt="png"></p><h3 id="Remove-bad-features-columns-and-records-row"><a href="#Remove-bad-features-columns-and-records-row" class="headerlink" title="Remove bad features (columns) and records (row)"></a>Remove bad features (columns) and records (row)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">row_na_rate</span><span class="params">(func_df)</span>:</span></span><br><span class="line">    bad_row = []</span><br><span class="line">    miss_num = []</span><br><span class="line">    <span class="keyword">for</span> each_row <span class="keyword">in</span> func_df.index:</span><br><span class="line">        miss_cnt = func_df.shape[<span class="number">1</span>]-func_df.iloc[each_row].count()</span><br><span class="line">        <span class="keyword">if</span> miss_cnt&gt;<span class="number">40</span>:</span><br><span class="line">            bad_row.append(each_row)</span><br><span class="line">        miss_num.append(miss_cnt)</span><br><span class="line">    <span class="keyword">return</span> bad_row, miss_num</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">col_na_rate</span><span class="params">(func_df)</span>:</span></span><br><span class="line">    bad_col = []</span><br><span class="line">    <span class="keyword">for</span> each_column <span class="keyword">in</span> func_df.columns:</span><br><span class="line">        miss_cnt = func_df.shape[<span class="number">0</span>]-func_df[each_column].count()</span><br><span class="line">        <span class="keyword">if</span> miss_cnt!=<span class="number">0</span>:          </span><br><span class="line">            <span class="keyword">if</span> miss_cnt/func_df.shape[<span class="number">0</span>]&gt;<span class="number">0.4</span>:</span><br><span class="line">                bad_col.append(each_column)</span><br><span class="line">    <span class="keyword">return</span> bad_col</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># get bad columns and rows</span></span><br><span class="line"><span class="comment"># and we do not need ID as a feature for the model</span></span><br><span class="line">remove_cols = col_na_rate(out_df_1000) + [<span class="string">'SK_ID_CURR'</span>]</span><br><span class="line">bad_row,miss_num  = row_na_rate(out_df_1000)</span><br><span class="line"><span class="comment"># plot how many 'na' the rows have.</span></span><br><span class="line">plt.hist(miss_num)</span><br></pre></td></tr></table></figure><pre><code>(array([9373., 2348., 2275., 2350., 1599.,  664.,  517., 8264., 9313.,        3017.]), array([ 0. ,  6.1, 12.2, 18.3, 24.4, 30.5, 36.6, 42.7, 48.8, 54.9, 61. ]), &lt;a list of 10 Patch objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/3.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out_df_1000 = out_df_1000.drop(bad_row,axis=<span class="number">0</span>).reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">print(Counter(out_df_1000.TARGET))</span><br></pre></td></tr></table></figure><pre><code>Counter({0: 10188, 1: 8768})</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">useful_col = [i <span class="keyword">for</span> i <span class="keyword">in</span> out_df_1000.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> remove_cols]</span><br><span class="line">train_usecol = out_df_1000[useful_col]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_usecol.shape</span><br></pre></td></tr></table></figure><pre><code>(18956, 72)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Counter(train_usecol.FLAG_OWN_REALTY)</span><br></pre></td></tr></table></figure><pre><code>Counter({&apos;Y&apos;: 13241, &apos;N&apos;: 5715})</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.FLAG_OWN_REALTY.dropna())</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x20aa7ac6388&gt;</code></pre><p><img src="/2019/10/11/Coding-Demonstration/4.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.FLAG_OWN_REALTY, hue=train_usecol.TARGET)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x20aa7d738c8&gt;</code></pre><p><img src="/2019/10/11/Coding-Demonstration/5.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.NAME_EDUCATION_TYPE, hue=train_usecol.TARGET)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0, 1, 2, 3, 4]), &lt;a list of 5 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/6.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">sns.countplot(train_usecol.NAME_INCOME_TYPE, hue=train_usecol.TARGET)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0, 1, 2, 3, 4, 5]), &lt;a list of 6 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/7.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">income_df = train_usecol</span><br><span class="line">income_series = income_df.groupby(<span class="string">'NAME_EDUCATION_TYPE'</span>).AMT_INCOME_TOTAL.mean()</span><br><span class="line">plt.bar(income_series.index, income_series)</span><br><span class="line">plt.xticks(rotation = <span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>([0, 1, 2, 3, 4], &lt;a list of 5 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/8.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">income_df = train_usecol</span><br><span class="line">income_series = income_df.groupby(<span class="string">'NAME_EDUCATION_TYPE'</span>).AMT_INCOME_TOTAL.mean()</span><br><span class="line">sns.barplot(income_series.index, income_series)</span><br><span class="line">plt.xticks(rotation = <span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0, 1, 2, 3, 4]), &lt;a list of 5 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/9.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.barplot(income_df.NAME_EDUCATION_TYPE,income_df.AMT_INCOME_TOTAL)</span><br><span class="line">plt.xticks(rotation = <span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0, 1, 2, 3, 4]), &lt;a list of 5 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/10.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.NAME_INCOME_TYPE, hue=train_usecol.TARGET)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0, 1, 2, 3, 4, 5]), &lt;a list of 6 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/11.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.FLAG_OWN_CAR, hue=train_usecol.TARGET)</span><br></pre></td></tr></table></figure><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x20aa8edef88&gt;</code></pre><p><img src="/2019/10/11/Coding-Demonstration/12.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.NAME_FAMILY_STATUS, hue=train_usecol.TARGET)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0, 1, 2, 3, 4]), &lt;a list of 5 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/13.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.NAME_HOUSING_TYPE, hue=train_usecol.TARGET)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0, 1, 2, 3, 4, 5]), &lt;a list of 6 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/14.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.OCCUPATION_TYPE, hue=train_usecol.TARGET)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,        17]), &lt;a list of 18 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/16.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.WEEKDAY_APPR_PROCESS_START, hue=train_usecol.TARGET)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0, 1, 2, 3, 4, 5, 6]), &lt;a list of 7 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/16.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.CNT_CHILDREN, hue=train_usecol.TARGET)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0, 1, 2, 3, 4, 5, 6, 7]), &lt;a list of 8 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/17.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(train_usecol.FLAG_MOBIL, hue=train_usecol.TARGET)</span><br><span class="line">plt.xticks(rotation=<span class="number">90</span>)</span><br></pre></td></tr></table></figure><pre><code>(array([0]), &lt;a list of 1 Text xticklabel objects&gt;)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/18.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_usecol.dtypes[:<span class="number">10</span>]</span><br><span class="line">train_usecol.dtypes[train_usecol.dtypes==<span class="string">'object'</span>].index</span><br></pre></td></tr></table></figure><pre><code>Index([&apos;NAME_CONTRACT_TYPE&apos;, &apos;CODE_GENDER&apos;, &apos;FLAG_OWN_CAR&apos;, &apos;FLAG_OWN_REALTY&apos;,       &apos;NAME_TYPE_SUITE&apos;, &apos;NAME_INCOME_TYPE&apos;, &apos;NAME_EDUCATION_TYPE&apos;,       &apos;NAME_FAMILY_STATUS&apos;, &apos;NAME_HOUSING_TYPE&apos;, &apos;OCCUPATION_TYPE&apos;,       &apos;WEEKDAY_APPR_PROCESS_START&apos;, &apos;ORGANIZATION_TYPE&apos;],      dtype=&apos;object&apos;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dummy_col_df</span><span class="params">(column_list, df)</span>:</span></span><br><span class="line">    not_dum_df = df[[i <span class="keyword">for</span> i <span class="keyword">in</span> df.columns <span class="keyword">if</span> i <span class="keyword">not</span> <span class="keyword">in</span> column_list]]</span><br><span class="line">    out_dummy_df = [not_dum_df]</span><br><span class="line">    <span class="keyword">for</span> each_column <span class="keyword">in</span> column_list:</span><br><span class="line">        out_dummy_df.append(pd.get_dummies(df[<span class="string">"OCCUPATION_TYPE"</span>],prefix=each_column[:<span class="number">4</span>]))</span><br><span class="line">    <span class="keyword">return</span> pd.concat(out_dummy_df, axis=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">dummy_list = [<span class="string">'OCCUPATION_TYPE'</span>, <span class="string">"WEEKDAY_APPR_PROCESS_START"</span>, <span class="string">'NAME_TYPE_SUITE'</span>, <span class="string">'NAME_INCOME_TYPE'</span>, <span class="string">'NAME_FAMILY_STATUS'</span>, </span><br><span class="line"><span class="string">'NAME_HOUSING_TYPE'</span>, <span class="string">'ORGANIZATION_TYPE'</span>]</span><br><span class="line"></span><br><span class="line">train_usecol_dummy = dummy_col_df(dummy_list,train_usecol)</span><br><span class="line">after_dummy_col=train_usecol_dummy.columns</span><br><span class="line">   </span><br><span class="line">train_usecol_fill = train_usecol_dummy.fillna(<span class="number">0</span>)</span><br><span class="line">train_usecol_fill.dtypes[train_usecol_fill.dtypes==<span class="string">'object'</span>].index</span><br><span class="line">    </span><br><span class="line"><span class="keyword">for</span> each_obj_col <span class="keyword">in</span> train_usecol_fill.dtypes[train_usecol_fill.dtypes == <span class="string">'object'</span>].index:</span><br><span class="line">    class_mapping = &#123;label: idx <span class="keyword">for</span> idx, label <span class="keyword">in</span> enumerate(sorted(</span><br><span class="line">        [i <span class="keyword">if</span> i != <span class="number">0</span> <span class="keyword">else</span> <span class="string">'0'</span> <span class="keyword">for</span> i <span class="keyword">in</span> list(set(train_usecol_fill[each_obj_col]))]))&#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'0'</span> <span class="keyword">in</span> class_mapping:</span><br><span class="line">        class_mapping[<span class="number">0</span>] = class_mapping[<span class="string">'0'</span>]</span><br><span class="line">    train_usecol_fill[each_obj_col] = train_usecol_fill[each_obj_col].map(class_mapping)</span><br><span class="line">    </span><br><span class="line">train_usecol_fill.shape</span><br></pre></td></tr></table></figure><pre><code>(18956, 191)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_usecol_fill.dtypes[train_usecol_fill.dtypes==<span class="string">'object'</span>].index</span><br></pre></td></tr></table></figure><pre><code>Index([], dtype=&apos;object&apos;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = train_usecol_fill[[i <span class="keyword">for</span> i <span class="keyword">in</span> after_dummy_col <span class="keyword">if</span> i != <span class="string">'TARGET'</span>]]</span><br><span class="line">y = train_usecol_fill.TARGET</span><br><span class="line"></span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=<span class="number">0.3</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">raw_log = LogisticRegression()</span><br><span class="line">raw_log.fit(x_train,y_train)</span><br><span class="line"></span><br><span class="line">print(raw_log.score(x_train,y_train))</span><br><span class="line">print(raw_log.score(x_test,y_test))</span><br></pre></td></tr></table></figure><pre><code>0.58045067450448420.5809741515737648</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test_df = pd.read_csv(<span class="string">'./input/application_test.csv'</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_usecol_dummy.shape</span><br></pre></td></tr></table></figure><pre><code>(18956, 191)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test_usecol = test_df[[i <span class="keyword">for</span> i <span class="keyword">in</span> useful_col <span class="keyword">if</span> i!=<span class="string">'TARGET'</span>]]</span><br><span class="line">test_usecol_dummy = dummy_col_df(dummy_list,test_usecol)</span><br><span class="line">test_usecol_fill = test_usecol_dummy.fillna(<span class="number">0</span>)</span><br><span class="line">test_usecol_fill.dtypes[test_usecol_fill.dtypes==<span class="string">'object'</span>].index</span><br></pre></td></tr></table></figure><pre><code>Index([&apos;NAME_CONTRACT_TYPE&apos;, &apos;CODE_GENDER&apos;, &apos;FLAG_OWN_CAR&apos;, &apos;FLAG_OWN_REALTY&apos;,       &apos;NAME_EDUCATION_TYPE&apos;],      dtype=&apos;object&apos;)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> each_obj_col <span class="keyword">in</span> test_usecol_fill.dtypes[test_usecol_fill.dtypes==<span class="string">'object'</span>].index:</span><br><span class="line">    class_mapping = &#123;label: idx <span class="keyword">for</span> idx, label <span class="keyword">in</span> enumerate(sorted(</span><br><span class="line">        [i <span class="keyword">if</span> i != <span class="number">0</span> <span class="keyword">else</span> <span class="string">'0'</span> <span class="keyword">for</span> i <span class="keyword">in</span> list(set(test_usecol_fill[each_obj_col]))])) &#125;</span><br><span class="line">    <span class="keyword">if</span> <span class="string">'0'</span> <span class="keyword">in</span> class_mapping:</span><br><span class="line">        class_mapping[<span class="number">0</span>] = class_mapping[<span class="string">'0'</span>]</span><br><span class="line">    test_usecol_fill[each_obj_col] = test_usecol_fill[each_obj_col].map(class_mapping)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">model = LogisticRegression()</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">8</span>)</span><br><span class="line">reduced_x = pca.fit_transform(x)</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(reduced_x,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">1</span>)</span><br><span class="line">model.fit(x_train,y_train)</span><br><span class="line">model.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.5797432741339898</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.svm <span class="keyword">import</span> SVC</span><br><span class="line">clf = SVC()</span><br><span class="line">reduced_x = pca.fit_transform(x)</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(reduced_x,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">1</span>)</span><br><span class="line">clf.fit(x_train,y_train)</span><br><span class="line">model.score(x_test,y_test)</span><br><span class="line">print(model.score)</span><br></pre></td></tr></table></figure><pre><code>&lt;bound method ClassifierMixin.score of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,                   intercept_scaling=1000, l1_ratio=None, max_iter=100,                   multi_class=&apos;warn&apos;, n_jobs=None, penalty=&apos;l2&apos;,                   random_state=None, solver=&apos;warn&apos;, tol=0.0001, verbose=0,                   warm_start=False)&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x_train,y_train)</span><br></pre></td></tr></table></figure><pre><code>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,                   intercept_scaling=1, l1_ratio=None, max_iter=100,                   multi_class=&apos;warn&apos;, n_jobs=None, penalty=&apos;l2&apos;,                   random_state=None, solver=&apos;warn&apos;, tol=0.0001, verbose=0,                   warm_start=False)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_n_pca</span><span class="params">(n_col)</span>:</span></span><br><span class="line">    model_score = []</span><br><span class="line">    <span class="keyword">for</span> this_n <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">30</span>):</span><br><span class="line">        model = LogisticRegression()</span><br><span class="line">        pca = PCA(n_components=this_n)</span><br><span class="line">        reduced_x = pca.fit_transform(x)</span><br><span class="line">        x_train,x_test,y_train,y_test = train_test_split(reduced_x,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">1</span>)</span><br><span class="line">        model.fit(x_train,y_train)</span><br><span class="line">        model_score.append(model.score(x_test,y_test))</span><br><span class="line">    <span class="keyword">return</span> model_score</span><br><span class="line"></span><br><span class="line">model_score = get_n_pca(x.shape[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.grid()</span><br><span class="line">plt.plot(range(<span class="number">1</span>,<span class="number">30</span>),model_score)</span><br><span class="line">print(*list((i+<span class="number">1</span>,j)<span class="keyword">for</span> i,j <span class="keyword">in</span> enumerate(model_score))[:<span class="number">20</span>],sep=<span class="string">'\n'</span>)</span><br><span class="line">print(<span class="string">'----'</span>)</span><br><span class="line">print(*list(zip(range(<span class="number">1</span>,<span class="number">30</span>),model_score))[:<span class="number">20</span>],sep=<span class="string">'\n'</span>)</span><br></pre></td></tr></table></figure><pre><code>(1, 0.5319148936170213)(2, 0.5291014594689643)(3, 0.5577633198522947)(4, 0.5649727448566907)(5, 0.5625109899771409)(6, 0.5746439247406365)(7, 0.5755231229119043)(8, 0.5797432741339898)(9, 0.5843151046245824)(10, 0.5846667838930895)(11, 0.5839634253560753)(12, 0.5846667838930895)(13, 0.5848426235273431)(14, 0.5841392649903289)(15, 0.5846667838930895)(16, 0.5841392649903289)(17, 0.584490944258836)(18, 0.5841392649903289)(19, 0.584490944258836)(20, 0.5841392649903289)----(1, 0.5319148936170213)(2, 0.5291014594689643)(3, 0.5577633198522947)(4, 0.5649727448566907)(5, 0.5625109899771409)(6, 0.5746439247406365)(7, 0.5755231229119043)(8, 0.5797432741339898)(9, 0.5843151046245824)(10, 0.5846667838930895)(11, 0.5839634253560753)(12, 0.5846667838930895)(13, 0.5848426235273431)(14, 0.5841392649903289)(15, 0.5846667838930895)(16, 0.5841392649903289)(17, 0.584490944258836)(18, 0.5841392649903289)(19, 0.584490944258836)(20, 0.5841392649903289)</code></pre><p><img src="/2019/10/11/Coding-Demonstration/19.png" alt="png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(model_score)</span><br></pre></td></tr></table></figure><pre><code>[0.5319148936170213, 0.5291014594689643, 0.5577633198522947, 0.5649727448566907, 0.5625109899771409, 0.5746439247406365, 0.5755231229119043, 0.5797432741339898, 0.5843151046245824, 0.5846667838930895, 0.5839634253560753, 0.5846667838930895, 0.5848426235273431, 0.5841392649903289, 0.5846667838930895, 0.5841392649903289, 0.584490944258836, 0.5841392649903289, 0.584490944258836, 0.5841392649903289, 0.5841392649903289, 0.584490944258836, 0.584490944258836, 0.5846667838930895, 0.5839634253560753, 0.5846667838930895, 0.584490944258836, 0.584490944258836, 0.584490944258836]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LogisticRegression</span><br><span class="line"></span><br><span class="line">model = LogisticRegression(intercept_scaling=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">pca = PCA(n_components=<span class="number">9</span>)</span><br><span class="line">reduced_x = pca.fit_transform(x)</span><br><span class="line">x_train,x_test,y_train,y_test = train_test_split(reduced_x,y,test_size=<span class="number">0.3</span>,random_state=<span class="number">1</span>)</span><br><span class="line">model.fit(x_train,y_train)</span><br><span class="line">model.score(x_test,y_test)</span><br></pre></td></tr></table></figure><pre><code>0.5881835765781607</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">out_x = test_usecol_fill</span><br><span class="line">reduced_out_x = pca.fit_transform(out_x)</span><br><span class="line">out_y=model.predict_proba(reduced_out_x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_y</span><br></pre></td></tr></table></figure><pre><code>array([[0.48863366, 0.51136634],       [0.51265858, 0.48734142],       [0.67984626, 0.32015374],       ...,       [0.56934672, 0.43065328],       [0.56985013, 0.43014987],       [0.50325753, 0.49674247]])</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out_df = pd.DataFrame(</span><br><span class="line">    &#123;<span class="string">'SK_ID_CURR'</span>:test_df.SK_ID_CURR.values, <span class="string">'TARGET'</span> : out_y.tolist&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out_df.to_csv(<span class="string">'out_df.csv'</span>, index=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Home-Credit&quot;&gt;&lt;a href=&quot;#Home-Credit&quot; class=&quot;headerlink&quot; title=&quot;Home Credit&quot;&gt;&lt;/a&gt;Home Credit&lt;/h1&gt;&lt;h2 id=&quot;Description&quot;&gt;&lt;a href=&quot;#Descri
      
    
    </summary>
    
    
    
  </entry>
  
  <entry>
    <title>Model-Optimization</title>
    <link href="http://yoursite.com/2019/08/12/Mode-Optimization/"/>
    <id>http://yoursite.com/2019/08/12/Mode-Optimization/</id>
    <published>2019-08-12T08:46:17.000Z</published>
    <updated>2019-11-12T09:04:23.360Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_auc_score</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> xgboost <span class="keyword">as</span> xgb</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBClassifier</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler, LabelEncoder</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score, roc_auc_score, confusion_matrix</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.feature_selection <span class="keyword">import</span> VarianceThreshold</span><br><span class="line">print(<span class="string">'Importing data...'</span>)</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">'../input/application_train.csv'</span>)</span><br><span class="line"></span><br><span class="line">test = pd.read_csv(<span class="string">'../input/application_test.csv'</span>)</span><br><span class="line"></span><br><span class="line">prev = pd.read_csv(<span class="string">'../input/previous_application.csv'</span>)</span><br><span class="line"></span><br><span class="line">buro = pd.read_csv(<span class="string">'../input/bureau.csv'</span>)</span><br><span class="line"></span><br><span class="line">buro_balance = pd.read_csv(<span class="string">'../input/bureau_balance.csv'</span>)</span><br><span class="line"></span><br><span class="line">credit_card  = pd.read_csv(<span class="string">'../input/credit_card_balance.csv'</span>)</span><br><span class="line"></span><br><span class="line">POS_CASH  = pd.read_csv(<span class="string">'../input/POS_CASH_balance.csv'</span>)</span><br><span class="line"></span><br><span class="line">payments = pd.read_csv(<span class="string">'../input/installments_payments.csv'</span>)</span><br><span class="line"></span><br><span class="line">lgbm_submission = pd.read_csv(<span class="string">'../input/sample_submission.csv'</span>)</span><br><span class="line">Importing data...</span><br><span class="line"><span class="comment">#Separate target variable</span></span><br><span class="line"></span><br><span class="line">y = data[<span class="string">'TARGET'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> data[<span class="string">'TARGET'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Feature engineering</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#data['loan_to_income'] = data.AMT_ANNUITY/data.AMT_INCOME_TOTAL</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#test['loan_to_income'] = test.AMT_ANNUITY/test.AMT_INCOME_TOTAL</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#One-hot encoding of categorical features in data and test sets</span></span><br><span class="line"></span><br><span class="line">categorical_features = [col <span class="keyword">for</span> col <span class="keyword">in</span> data.columns <span class="keyword">if</span> data[col].dtype == <span class="string">'object'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">one_hot_df = pd.concat([data,test])</span><br><span class="line"></span><br><span class="line">one_hot_df = pd.get_dummies(one_hot_df, columns=categorical_features)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = one_hot_df.iloc[:data.shape[<span class="number">0</span>],:]</span><br><span class="line"></span><br><span class="line">test = one_hot_df.iloc[data.shape[<span class="number">0</span>]:,]</span><br><span class="line"><span class="comment">#Pre-processing buro_balance</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Pre-processing buro_balance...'</span>)</span><br><span class="line"></span><br><span class="line">buro_grouped_size = buro_balance.groupby(<span class="string">'SK_ID_BUREAU'</span>)[<span class="string">'MONTHS_BALANCE'</span>].size()</span><br><span class="line"></span><br><span class="line">buro_grouped_max = buro_balance.groupby(<span class="string">'SK_ID_BUREAU'</span>)[<span class="string">'MONTHS_BALANCE'</span>].max()</span><br><span class="line"></span><br><span class="line">buro_grouped_min = buro_balance.groupby(<span class="string">'SK_ID_BUREAU'</span>)[<span class="string">'MONTHS_BALANCE'</span>].min()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">buro_counts = buro_balance.groupby(<span class="string">'SK_ID_BUREAU'</span>)[<span class="string">'STATUS'</span>].value_counts(normalize = <span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">buro_counts_unstacked = buro_counts.unstack(<span class="string">'STATUS'</span>)</span><br><span class="line"></span><br><span class="line">buro_counts_unstacked.columns = [<span class="string">'STATUS_0'</span>, <span class="string">'STATUS_1'</span>,<span class="string">'STATUS_2'</span>,<span class="string">'STATUS_3'</span>,<span class="string">'STATUS_4'</span>,<span class="string">'STATUS_5'</span>,<span class="string">'STATUS_C'</span>,<span class="string">'STATUS_X'</span>,]</span><br><span class="line"></span><br><span class="line">buro_counts_unstacked[<span class="string">'MONTHS_COUNT'</span>] = buro_grouped_size</span><br><span class="line"></span><br><span class="line">buro_counts_unstacked[<span class="string">'MONTHS_MIN'</span>] = buro_grouped_min</span><br><span class="line"></span><br><span class="line">buro_counts_unstacked[<span class="string">'MONTHS_MAX'</span>] = buro_grouped_max</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">buro = buro.join(buro_counts_unstacked, how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_BUREAU'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Pre-processing previous_application</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Pre-processing previous_application...'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#One-hot encoding of categorical features in previous application data set</span></span><br><span class="line"></span><br><span class="line">prev_cat_features = [pcol <span class="keyword">for</span> pcol <span class="keyword">in</span> prev.columns <span class="keyword">if</span> prev[pcol].dtype == <span class="string">'object'</span>]</span><br><span class="line"></span><br><span class="line">prev = pd.get_dummies(prev, columns=prev_cat_features)</span><br><span class="line"></span><br><span class="line">avg_prev = prev.groupby(<span class="string">'SK_ID_CURR'</span>).mean()</span><br><span class="line"></span><br><span class="line">cnt_prev = prev[[<span class="string">'SK_ID_CURR'</span>, <span class="string">'SK_ID_PREV'</span>]].groupby(<span class="string">'SK_ID_CURR'</span>).count()</span><br><span class="line"></span><br><span class="line">avg_prev[<span class="string">'nb_app'</span>] = cnt_prev[<span class="string">'SK_ID_PREV'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> avg_prev[<span class="string">'SK_ID_PREV'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Pre-processing buro</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Pre-processing buro...'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#One-hot encoding of categorical features in buro data set</span></span><br><span class="line"></span><br><span class="line">buro_cat_features = [bcol <span class="keyword">for</span> bcol <span class="keyword">in</span> buro.columns <span class="keyword">if</span> buro[bcol].dtype == <span class="string">'object'</span>]</span><br><span class="line"></span><br><span class="line">buro = pd.get_dummies(buro, columns=buro_cat_features)</span><br><span class="line"></span><br><span class="line">avg_buro = buro.groupby(<span class="string">'SK_ID_CURR'</span>).mean()</span><br><span class="line"></span><br><span class="line">avg_buro[<span class="string">'buro_count'</span>] = buro[[<span class="string">'SK_ID_BUREAU'</span>, <span class="string">'SK_ID_CURR'</span>]].groupby(<span class="string">'SK_ID_CURR'</span>).count()[<span class="string">'SK_ID_BUREAU'</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> avg_buro[<span class="string">'SK_ID_BUREAU'</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Pre-processing POS_CASH</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Pre-processing POS_CASH...'</span>)</span><br><span class="line"></span><br><span class="line">le = LabelEncoder()</span><br><span class="line"></span><br><span class="line">POS_CASH[<span class="string">'NAME_CONTRACT_STATUS'</span>] = le.fit_transform(POS_CASH[<span class="string">'NAME_CONTRACT_STATUS'</span>].astype(str))</span><br><span class="line"></span><br><span class="line">nunique_status = POS_CASH[[<span class="string">'SK_ID_CURR'</span>, <span class="string">'NAME_CONTRACT_STATUS'</span>]].groupby(<span class="string">'SK_ID_CURR'</span>).nunique()</span><br><span class="line"></span><br><span class="line">nunique_status2 = POS_CASH[[<span class="string">'SK_ID_CURR'</span>, <span class="string">'NAME_CONTRACT_STATUS'</span>]].groupby(<span class="string">'SK_ID_CURR'</span>).max()</span><br><span class="line"></span><br><span class="line">POS_CASH[<span class="string">'NUNIQUE_STATUS'</span>] = nunique_status[<span class="string">'NAME_CONTRACT_STATUS'</span>]</span><br><span class="line"></span><br><span class="line">POS_CASH[<span class="string">'NUNIQUE_STATUS2'</span>] = nunique_status2[<span class="string">'NAME_CONTRACT_STATUS'</span>]</span><br><span class="line"></span><br><span class="line">POS_CASH.drop([<span class="string">'SK_ID_PREV'</span>, <span class="string">'NAME_CONTRACT_STATUS'</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Pre-processing credit_card</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Pre-processing credit_card...'</span>)</span><br><span class="line"></span><br><span class="line">credit_card[<span class="string">'NAME_CONTRACT_STATUS'</span>] = le.fit_transform(credit_card[<span class="string">'NAME_CONTRACT_STATUS'</span>].astype(str))</span><br><span class="line"></span><br><span class="line">nunique_status = credit_card[[<span class="string">'SK_ID_CURR'</span>, <span class="string">'NAME_CONTRACT_STATUS'</span>]].groupby(<span class="string">'SK_ID_CURR'</span>).nunique()</span><br><span class="line"></span><br><span class="line">nunique_status2 = credit_card[[<span class="string">'SK_ID_CURR'</span>, <span class="string">'NAME_CONTRACT_STATUS'</span>]].groupby(<span class="string">'SK_ID_CURR'</span>).max()</span><br><span class="line"></span><br><span class="line">credit_card[<span class="string">'NUNIQUE_STATUS'</span>] = nunique_status[<span class="string">'NAME_CONTRACT_STATUS'</span>]</span><br><span class="line"></span><br><span class="line">credit_card[<span class="string">'NUNIQUE_STATUS2'</span>] = nunique_status2[<span class="string">'NAME_CONTRACT_STATUS'</span>]</span><br><span class="line"></span><br><span class="line">credit_card.drop([<span class="string">'SK_ID_PREV'</span>, <span class="string">'NAME_CONTRACT_STATUS'</span>], axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Pre-processing payments</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Pre-processing payments...'</span>)</span><br><span class="line"></span><br><span class="line">avg_payments = payments.groupby(<span class="string">'SK_ID_CURR'</span>).mean()</span><br><span class="line"></span><br><span class="line">avg_payments2 = payments.groupby(<span class="string">'SK_ID_CURR'</span>).max()</span><br><span class="line"></span><br><span class="line">avg_payments3 = payments.groupby(<span class="string">'SK_ID_CURR'</span>).min()</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> avg_payments[<span class="string">'SK_ID_PREV'</span>]</span><br><span class="line">Pre-processing buro_balance...</span><br><span class="line">Pre-processing previous_application...</span><br><span class="line">Pre-processing buro...</span><br><span class="line">Pre-processing POS_CASH...</span><br><span class="line">Pre-processing credit_card...</span><br><span class="line">Pre-processing payments...</span><br><span class="line"><span class="comment">#Join data bases</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Joining databases...'</span>)</span><br><span class="line"></span><br><span class="line">data = data.merge(right=avg_prev.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line">test = test.merge(right=avg_prev.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.merge(right=avg_buro.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line">test = test.merge(right=avg_buro.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.merge(POS_CASH.groupby(<span class="string">'SK_ID_CURR'</span>).mean().reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line">test = test.merge(POS_CASH.groupby(<span class="string">'SK_ID_CURR'</span>).mean().reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.merge(credit_card.groupby(<span class="string">'SK_ID_CURR'</span>).mean().reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line">test = test.merge(credit_card.groupby(<span class="string">'SK_ID_CURR'</span>).mean().reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.merge(right=avg_payments.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line">test = test.merge(right=avg_payments.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.merge(right=avg_payments2.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line">test = test.merge(right=avg_payments2.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">data = data.merge(right=avg_payments3.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line"></span><br><span class="line">test = test.merge(right=avg_payments3.reset_index(), how=<span class="string">'left'</span>, on=<span class="string">'SK_ID_CURR'</span>)</span><br><span class="line">Joining databases...</span><br><span class="line"><span class="comment">#Remove features with many missing values</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Removing features with more than 80% missing...'</span>)</span><br><span class="line"></span><br><span class="line">test = test[test.columns[data.isnull().mean() &lt; <span class="number">0.85</span>]]</span><br><span class="line"></span><br><span class="line">data = data[data.columns[data.isnull().mean() &lt; <span class="number">0.85</span>]]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">excluded_feats = [<span class="string">'SK_ID_CURR'</span>]</span><br><span class="line"></span><br><span class="line">features = [f_ <span class="keyword">for</span> f_ <span class="keyword">in</span> data.columns <span class="keyword">if</span> f_ <span class="keyword">not</span> <span class="keyword">in</span> excluded_feats]</span><br><span class="line">Removing features <span class="keyword">with</span> more than <span class="number">80</span>% missing...</span><br><span class="line">folds = KFold(n_splits=<span class="number">4</span>, shuffle=<span class="literal">True</span>, random_state=<span class="number">546789</span>)</span><br><span class="line"></span><br><span class="line">oof_preds = np.zeros(data.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">sub_preds = np.zeros(test.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> n_fold, (trn_idx, val_idx) <span class="keyword">in</span> enumerate(folds.split(data)):</span><br><span class="line"></span><br><span class="line">    trn_x, trn_y = data[features].iloc[trn_idx], y.iloc[trn_idx]</span><br><span class="line"></span><br><span class="line">    val_x, val_y = data[features].iloc[val_idx], y.iloc[val_idx]</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    clf = XGBClassifier(</span><br><span class="line"></span><br><span class="line">        objective = <span class="string">'binary:logistic'</span>, </span><br><span class="line"></span><br><span class="line">        booster = <span class="string">"gbtree"</span>,</span><br><span class="line"></span><br><span class="line">        eval_metric = <span class="string">'auc'</span>, </span><br><span class="line"></span><br><span class="line">        nthread = <span class="number">4</span>,</span><br><span class="line"></span><br><span class="line">        eta = <span class="number">0.05</span>,</span><br><span class="line"></span><br><span class="line">        gamma = <span class="number">0</span>,</span><br><span class="line"></span><br><span class="line">        max_depth = <span class="number">6</span>, </span><br><span class="line"></span><br><span class="line">        subsample = <span class="number">0.7</span>, </span><br><span class="line"></span><br><span class="line">        colsample_bytree = <span class="number">0.7</span>, </span><br><span class="line"></span><br><span class="line">        colsample_bylevel = <span class="number">0.675</span>,</span><br><span class="line"></span><br><span class="line">        min_child_weight = <span class="number">22</span>,</span><br><span class="line"></span><br><span class="line">        alpha = <span class="number">0</span>,</span><br><span class="line"></span><br><span class="line">        random_state = <span class="number">42</span>, </span><br><span class="line"></span><br><span class="line">        nrounds = <span class="number">2000</span>,</span><br><span class="line">        </span><br><span class="line">        n_estimators=<span class="number">2000</span></span><br><span class="line"></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    clf.fit(trn_x, trn_y, eval_set= [(trn_x, trn_y), (val_x, val_y)], verbose=<span class="number">10</span>, early_stopping_rounds=<span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    oof_preds[val_idx] = clf.predict_proba(val_x)[:, <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    sub_preds += clf.predict_proba(test[features])[:, <span class="number">1</span>] / folds.n_splits</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Fold %2d AUC : %.6f'</span> % (n_fold + <span class="number">1</span>, roc_auc_score(val_y, oof_preds[val_idx])))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">del</span> clf, trn_x, trn_y, val_x, val_y</span><br><span class="line"></span><br><span class="line">    gc.collect()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># take too long time, break after the first loop with primitive result.</span></span><br><span class="line">    <span class="keyword">break</span></span><br></pre></td></tr></table></figure><p><img src="/2019/08/12/Mode-Optimization/1.png" alt="1"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'Full AUC score %.6f'</span> % roc_auc_score(y, oof_preds))   </span><br><span class="line"></span><br><span class="line">test[<span class="string">'TARGET'</span>] = sub_preds</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">test[[<span class="string">'SK_ID_CURR'</span>, <span class="string">'TARGET'</span>]].to_csv(<span class="string">'xgb_submission_esi.csv'</span>, index=<span class="literal">False</span>, float_format=<span class="string">'%.8f'</span>)</span><br><span class="line">Full AUC score <span class="number">0.518708</span></span><br></pre></td></tr></table></figure><p><a href="xgb_submission_esi.csv">Click here to download my data file</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
